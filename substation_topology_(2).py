# -*- coding: utf-8 -*-
"""Substation_Topology (2).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wBbF2-O-IkoqtG797Q-SzDYxPSkJjEPa
"""


import grid2op
from grid2op.PlotGrid import PlotMatplot
import numpy as np
import pickle
import pandas as pd
from tqdm import trange
from grid2op.dtypes import dt_int, dt_float, dt_bool


import os
from grid2op import make

env = make("l2rpn_neurips_2020_track1_small")

plot_helper = PlotMatplot(env.observation_space)

obs = env.reset()
# print("Observation/State:", obs, "\n")
fig = plot_helper.plot_obs(obs)

pickle_in = open("sub_all_possible_scenario",'rb')

sub_topo_configuration = pickle.load(pickle_in)

pickle_out_2 = open("substation_bus_all_combination",'rb')

action_topology = pickle.load(pickle_out_2)

def sub_action(obs,actions_topology):
  obj = {}
  for j in range(obs.n_sub):
    obj['sub_'+str(j)] = actions_topology[j][1]
  listed = [(k, v) for k, v in obj.items()]

  tested_action = []
  for i in range(obs.n_sub):
    sub_action = []
    for j in range(len(listed[i][1])):
      actions= listed[i][1][j]
      act = env.action_space({"set_bus":{ "substations_id": [(i, actions)]}})
      sub_action.append(act)
    tested_action.append((i,sub_action))

  return tested_action,listed

def sub_action_encoding(obs, action_topology):
    tested_action = []
    for i in range(obs.n_sub):
        sub_actions = []
        for j in range(len(action_topology[i][1])):
            actions = action_topology[i][1][j]
            act = env.action_space({"set_bus":{ "substations_id": [(i, actions)]}})
            sub_actions.append(act)
        tested_action.append((i,sub_actions))
    return tested_action

tested_action = sub_action_encoding(obs, action_topology)

do_nothing = env.action_space({})

# print(len(tested_action[12][1]))


    
    
def choose_best_action_by_simul(observation,seeds,tested_action,do_nothing):
  best_action, highest_reward, survived_steps= [], [],[]
  tested_action = tested_action
  env = make("l2rpn_neurips_2020_track1_small")
  obs = env.reset()
  steps = []

  if len((tested_action))  > 1:
      
      for l in trange(len(seeds)):
          resulting_reward = np.full(shape = len(tested_action), fill_value=np.NaN, dtype = dt_float)
          seed = seeds[l]
          
          for i, action in enumerate(tested_action):
              
              step = 0
              done = False
              total_reward = []
              
              env = make("l2rpn_neurips_2020_track1_small")
              env.seed(seed)
              obs = env.reset()
              
              obs, reward, done, info = env.step(action)
              step += 1
              
              if done:                  
                  print("_________________EPISODE OVER_______________",step)
              total_reward.append(reward/1000)
            
              while not done: 
                  obs, reward, done, info = env.step(do_nothing)
                  step += 1
                  total_reward.append(reward/1000)
              simu_rewards = np.sum(total_reward)
              resulting_reward[i]= simu_rewards
              steps.append(step)
              reward_idx = np.argsort(resulting_reward)
          for k in range(len(reward_idx)):
              
              best_action.append(tested_action[reward_idx[k]])
              highest_reward.append(resulting_reward[reward_idx[k]])
  return best_action, highest_reward,steps
    

env = make("l2rpn_neurips_2020_track1_small")
obs = env.reset()
do_nothing = env.action_space({})
# fig = plot_helper.plot_obs(obs)

seeds = np.arange(10)

scenario = tested_action[16][1]

acti,rewards,steps = choose_best_action_by_simul(obs,seeds,scenario,do_nothing) # 1,4,7,9,23 ### randomised seed


step = np.array(steps).reshape(len(seeds),len(tested_action[16][1]))


# print(steps)

column = np.arange(10)
DF = (pd.DataFrame(step.T))
DF.to_csv("sub 16.csv",index = False)

